{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import sys\n",
    "from pyknp import KNP\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定義\n",
    "mode_id = 1 # 1；抽出方法1/ 2：抽出方法2\n",
    "\n",
    "data_size = 215 # データタイズ\n",
    "skip_file = [107,129,125,151,173,195] # スキップファイル\n",
    "\n",
    "file_info = \"./data/input/RS_data/rsdata\" # アノテーションデータのPATH\n",
    "result_path = \"./data/output/Chapter5\" # 出力ファイルのPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_fix(text):\n",
    "    text = text.replace(\" \",\"　\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正解アノテーションの単語を返す\n",
    "def load_ann(file_ann):\n",
    "\n",
    "    true_wh_dic = {\"WHERE\":[], \"WHEN\":[], \"WHO\":[], \"WHAT\":[], \"HOW\":[], \"WHY\":[],\"SERIF\":[]}\n",
    "    \n",
    "    # アノテーションデータ読み込み・保存\n",
    "    with open(file_ann, 'r') as f:\n",
    "        for i in f.read().split(\"\\n\"):\n",
    "            if len(i) != 0:\n",
    "                label_name = i.split()[1]\n",
    "                true_s = int(i.split()[2])\n",
    "                true_e = int(i.split()[3])-1\n",
    "                true_word = i.split()[4]\n",
    "                true_wh_dic[label_name].append([true_word,[true_s,true_e]])                    \n",
    "    return true_wh_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NERと評価語の構文解析結果を保存\n",
    "\n",
    "入力：文章\n",
    "出力：構文解析結果の辞書,NER該当リスト\n",
    "\n",
    "\"\"\"\n",
    "def save_bnst(line,word_count):\n",
    "    \n",
    "    result_data = []\n",
    "    \n",
    "    bnst_dic ={}    \n",
    "    ner_list = []\n",
    "    verb_list = []\n",
    "    \n",
    "    child_list=[]\n",
    "    parent_list=[]\n",
    "        \n",
    "    knp = KNP()\n",
    "    result = knp.parse(data_fix(line)) \n",
    "    for bnst in result.bnst_list(): # 文節\n",
    "        \n",
    "        ner_flag = False\n",
    "        verb_flag = False\n",
    "        word_list = []\n",
    "        wc_l = []\n",
    "        hinshi_list = []\n",
    "        ner_info = []\n",
    "        dic_value ={}\n",
    "        \n",
    "        mrph_list = bnst.mrph_list()        \n",
    "        for mrph in mrph_list: # 形態素 \n",
    "            \n",
    "            # 単語数情報\n",
    "            if len(mrph.midasi) > 1: # 単語サイズ\n",
    "                wc = []\n",
    "                for i in range(len(mrph.midasi)):                    \n",
    "                    word_count += 1\n",
    "                    wc.append(word_count)\n",
    "                wc_l.append(wc)\n",
    "            else:\n",
    "                word_count += 1\n",
    "                wc_l.append(word_count)\n",
    "            \n",
    "            # NER情報\n",
    "            if \"NE:\" in mrph.fstring: # NERのときの処理 \n",
    "                ner_info.append(re.search(r\"<NE:(.*?)>\",mrph.fstring).group(1))\n",
    "                ner_flag = True\n",
    "            else:\n",
    "                ner_info.append(\"\")\n",
    "\n",
    "            # 品詞情報と単語情報\n",
    "            if \"■■\" in mrph.midasi: # 括弧の中身は、品詞情報を「特殊」にする\n",
    "                word_list.append(mrph.midasi)\n",
    "                hinshi_list.append(\"特殊\")\n",
    "            else: \n",
    "                word_list.append(mrph.midasi)\n",
    "                hinshi_list.append(mrph.hinsi)    \n",
    "            \n",
    "            # 動詞情報リスト作成のため\n",
    "            if \"動詞\" in mrph.hinsi:\n",
    "                verb_flag = True\n",
    "\n",
    "        # 辞書追加\n",
    "        dic_value[\"parent_id\"] = bnst.parent_id\n",
    "        dic_value[\"word_id\"] = wc_l\n",
    "        dic_value[\"word\"] = word_list       \n",
    "        dic_value[\"hinsi\"] = hinshi_list\n",
    "        dic_value[\"ner\"] =  ner_info        \n",
    "        \n",
    "        # NER情報\n",
    "        if ner_flag:\n",
    "            ner_list.append(bnst.bnst_id)\n",
    "            \n",
    "        # 動詞情報\n",
    "        if verb_flag:\n",
    "            verb_list.append(bnst.bnst_id)\n",
    "        \n",
    "        bnst_dic[bnst.bnst_id] = dic_value\n",
    "   \n",
    "    return bnst_dic,ner_list,verb_list,word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "係り受け関係のid順を取得する\n",
    "\n",
    "入力：構文解析結果の辞書 \n",
    "出力：係り受け関係のid順\n",
    "\n",
    "\"\"\"                            \n",
    "def get_bnst_order(bnst_dic):\n",
    "\n",
    "    bnst_order_dic = {}\n",
    "\n",
    "    # 1. 全ての文節の係り受け順(id)を取得する\n",
    "    for my_id in bnst_dic.keys():\n",
    "\n",
    "        flag = True\n",
    "        my_list=[my_id]\n",
    "        serch_id = my_id\n",
    "\n",
    "        # 1-1. 文節ごとに、最後の係り先になるまでループする\n",
    "        while flag:\n",
    "            parent_id = bnst_dic[serch_id][\"parent_id\"]\n",
    "\n",
    "            if parent_id != -1: # 係り先が最後じゃないとき、係り先のidを格納\n",
    "                my_list.append(bnst_dic[serch_id][\"parent_id\"])\n",
    "                \n",
    "            else: # 係り先が最後のとき、ループを抜ける\n",
    "                flag = False\n",
    "                \n",
    "            serch_id = parent_id # 1-2.係り先のidを次の探索idとする\n",
    "            \n",
    "        bnst_order_dic[my_id]  = my_list # 1-3.文節ごとに、係り受け順を格納\n",
    "    \n",
    "    return bnst_order_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "最後の係り元idを取得する\n",
    "\n",
    "入力：構文解析結果の辞書\n",
    "出力：最後の係り元idを取得     \n",
    "\n",
    "\"\"\"\n",
    "def get_bnst_end(bnst_dic):\n",
    "    \n",
    "    end_list = []\n",
    "\n",
    "    # 1. 文節ごとに、他の文節の親になっているか調べる\n",
    "    for my_id in bnst_dic.keys():\n",
    "\n",
    "        # 1-1. 他の文節の親を調査\n",
    "        for value in bnst_dic.values():\n",
    "            \n",
    "            if my_id == value[\"parent_id\"]: # 文節の親になっている場合、false\n",
    "                flag = False\n",
    "                break\n",
    "            else: # 文節の親になっていない場合、true\n",
    "                flag = True\n",
    "\n",
    "        if flag:\n",
    "            end_list.append(my_id) # リストに追加する\n",
    "            \n",
    "    return end_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ターゲット単語の左側のidを取得する\n",
    "\n",
    "入力：構文解析結果の辞書、係り受け関係のid順、ターゲットid\n",
    "出力：ターゲット単語の左側のid (複数あり)\n",
    "\n",
    "\"\"\"\n",
    "def get_bnst_left(bnst_dic,bnst_order_dic,keyword_id):\n",
    "    \n",
    "    bnst_left = []\n",
    "    end_list = get_bnst_end(bnst_dic)\n",
    "\n",
    "    # 1. 係り受けルートにターゲット単語あったとき、左側の単語を取得\n",
    "    for i in end_list:\n",
    "        serch_list = bnst_order_dic[i]\n",
    "\n",
    "        # 1-2. 係り受けルートにターゲット単語があるか調べる\n",
    "        if keyword_id in serch_list:\n",
    "            p = serch_list.index(keyword_id)            \n",
    "            if p != 0:\n",
    "                tmp_list = []\n",
    "                \n",
    "                # 1-3. ターゲット単語の左側の単語を取得\n",
    "                for j in range(p+1):\n",
    "                    left_id = serch_list[j]\n",
    "                    tmp_list.append(left_id)\n",
    "\n",
    "                #1-4. 取得したものをリストに格納\n",
    "                bnst_left.append(tmp_list)\n",
    "            else:\n",
    "                bnst_left.append([0])\n",
    "        \n",
    "    return bnst_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "評価用\n",
    "入力：正解データ辞書、予測データ辞書\n",
    "出力： 5W1Hごとの失敗パターン辞書\n",
    "    - 完全： 正解チャンク\n",
    "    - 一部一致： 正解チャンク, 予測チャンク\n",
    "    - ラベル誤り：正解チャンク, 予測チャンク, 正解ラベル, 予測ラベル\n",
    "    - 抽出漏れ： 正解チャンク\n",
    "    - 過度の抽出： 予測チャンク\n",
    "    \n",
    "\"\"\"\n",
    "def eval_report(true_wh_dic,pred_wh_dic):\n",
    "    report_data = {}\n",
    "\n",
    "    # 予測ラベルのマッチングチェックリスト (マッチしたら1)\n",
    "    check_pred_dic = {}\n",
    "    for k,v in pred_wh_dic.items():\n",
    "        check_pred = [0 for i in range(len(v))]\n",
    "        check_pred_dic[k] = check_pred\n",
    "        \n",
    "    # 正解ラベルのマッチングリスト\n",
    "    check_true_dic = {}\n",
    "    for k,v in true_wh_dic.items():\n",
    "        check_true = [0 for i in range(len(v))]\n",
    "        check_true_dic[k] = check_true\n",
    "        \n",
    "    for k,v in true_wh_dic.items():\n",
    "        report_v = {}\n",
    "        result_type1 = []\n",
    "        result_type2 = []\n",
    "        result_type3 = []\n",
    "        \n",
    "        for t_num, true_text in enumerate(v):\n",
    "            true_id = [i for i in range(true_text[1][0],(true_text[1][1])+1)]   \n",
    "            \n",
    "            for anoter_pk,anoter_pts in pred_wh_dic.items(): # すべての予想ラベルから検索\n",
    "                 for p_num, anoter_pt in enumerate(anoter_pts):\n",
    "                        \n",
    "                        pred_id = anoter_pt[1]\n",
    "                        match_n = list(set(true_id) & set(pred_id))  \n",
    "                        \n",
    "                        if k == anoter_pk and len(match_n) > 0: # 予想も正解もチャンクとラベルが同じ\n",
    "                            if len(true_id) == len(pred_id):\n",
    "                                check_pred_dic[k][p_num] = 1 \n",
    "                                check_true_dic[k][t_num] = 1\n",
    "                                result_type1.append(true_text[0]) # 完全\n",
    "                            else:\n",
    "                                check_pred_dic[k][p_num] = 1 \n",
    "                                check_true_dic[k][t_num] = 1\n",
    "                                result_type2.append([true_text[0],anoter_pt[0]]) #一部一致\n",
    "                                \n",
    "                        if k != anoter_pk and len(match_n) > 0: # 予想も正解もチャンクは同じだが、ラベルが違う\n",
    "                            result_type3.append([true_text[0],anoter_pt[0],k,anoter_pk]) # ラベルミス\n",
    "                            check_pred_dic[anoter_pk][p_num] = 1 \n",
    "                            check_true_dic[k][t_num] = 1\n",
    "                        \n",
    "        report_v[\"完全\"] = result_type1\n",
    "        report_v[\"一部一致\"] = result_type2\n",
    "        report_v[\"ラベル誤り\"] = result_type3\n",
    "        report_v[\"抽出漏れ\"] = []\n",
    "        report_v[\"過度の抽出\"] = []\n",
    "        report_data[k] = report_v\n",
    "    \n",
    "    # 抽出漏れの処理\n",
    "    for k,v in check_true_dic.items():        \n",
    "        noexits_ture = [i for i,c in enumerate(v) if c == 0]        \n",
    "        if len(noexits_ture) > 0:\n",
    "            for i in noexits_ture:\n",
    "                report_data[k][\"抽出漏れ\"].append(true_wh_dic[k][i][0]) # 抽出漏れ\n",
    "                \n",
    "    \n",
    "    # 誤予測の処理\n",
    "    for k,v in check_pred_dic.items():        \n",
    "        miss_pred = [i for i,c in enumerate(v) if c == 0]        \n",
    "        if len(miss_pred) > 0:\n",
    "            for i in miss_pred:\n",
    "                report_data[k][\"過度の抽出\"].append(pred_wh_dic[k][i][0]) # 誤予測\n",
    "\n",
    "    return report_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4タイプの結果の数を集計する\n",
    "入力：ファイルid、4タイプの結果、ラベル\n",
    "出力：1つのファイルにおけるタイプごとの結果数\n",
    "\"\"\"\n",
    "def cal_report(file_id,result,wh_label):\n",
    "    wh_num = [0 for i in range(6)]\n",
    "    wh_num[0] = file_id\n",
    "    for wh in wh_label:\n",
    "        for k,v in result[wh].items():\n",
    "            if k == \"完全\":\n",
    "                wh_num[1] += len(v)\n",
    "            elif k == \"一部一致\":\n",
    "                wh_num[2] += len(v)\n",
    "            elif k == \"ラベル誤り\":\n",
    "                wh_num[3] += len(v)\n",
    "            elif k == \"抽出漏れ\":\n",
    "                wh_num[4] += len(v)\n",
    "            elif k == \"過度の抽出\":\n",
    "                wh_num[5] += len(v)\n",
    "                    \n",
    "    return wh_num  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "全タイプの結果の数を集計する\n",
    "入力：ファイルid、4タイプの結果、ラベル\n",
    "出力：1つのファイルにおける、ラベルごとのタイプごとの結果数\n",
    "\"\"\"\n",
    "def cal_report_wh(file_id,result):\n",
    "    report_data= {}\n",
    "    for label,wh_value in result.items():\n",
    "        \n",
    "        wh_num = [0 for i in range(6)]\n",
    "        wh_num[0] = file_id\n",
    "        for rtype,value in wh_value.items():\n",
    "            if rtype == \"完全\":\n",
    "                wh_num[1] += len(value)\n",
    "            elif rtype == \"一部一致\":\n",
    "                wh_num[2] += len(value)\n",
    "            elif rtype == \"ラベル誤り\":\n",
    "                wh_num[3] += len(value)    \n",
    "            elif rtype == \"抽出漏れ\":\n",
    "                wh_num[4] += len(value)\n",
    "            elif rtype == \"過度の抽出\":\n",
    "                wh_num[5] += len(value)\n",
    "            \n",
    "        report_data[label] = wh_num\n",
    "        \n",
    "    return report_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WHO, WHEN, WHEREをknpで抽出する\n",
    "\"\"\"\n",
    "def extraction_3w(bnst_dic,ner_list,wh_dic,pred_wh_dic):\n",
    "\n",
    "    w_ner_word = \"\"\n",
    "    w_ner_wc = []\n",
    "    ner_flag = False\n",
    "                \n",
    "    ner_list = sorted(ner_list) # 昇順 \n",
    "    for ner_id in ner_list:\n",
    "        ner = bnst_dic[ner_id][\"ner\"]\n",
    "        # NERのフラグ管理\n",
    "        if any(s.endswith(\":B\") for s in ner) and any(s.endswith(\":E\") for s in ner):\n",
    "            ner_flag = True\n",
    "        if any(s.endswith(\":S\") for s in ner):\n",
    "            ner_flag = True\n",
    "                                        \n",
    "        # 1文節でNER情報が簡潔している\n",
    "        if ner_flag:\n",
    "            ner_word = \"\"\n",
    "            ner_wc = []\n",
    "            ner_flag = False # ner\n",
    "            for i,ner_label in enumerate(ner):\n",
    "                if \":S\" in ner_label: # 固有表現が一つ\n",
    "                    ner_word += bnst_dic[ner_id][\"word\"][i]\n",
    "                    w_i = bnst_dic[ner_id][\"word_id\"][i]\n",
    "                    \n",
    "                    if type(w_i) is list:\n",
    "                        for j in w_i:\n",
    "                            ner_wc.append(j)\n",
    "                    else:\n",
    "                        ner_wc.append(w_i)\n",
    "                                \n",
    "                    label = ner_label.replace(\":S\",\"\")\n",
    "                    if label in wh_dic:\n",
    "                        label_name = wh_dic[label]\n",
    "                        pred_wh_dic[label_name].append([ner_word,ner_wc]) # データ保存\n",
    "                                \n",
    "                    # 初期化\n",
    "                    ner_word = \"\"\n",
    "                    ner_wc = []\n",
    "                                \n",
    "                elif \":E\" in ner_label: # 最後の固有表現\n",
    "                    ner_word += bnst_dic[ner_id][\"word\"][i]   \n",
    "                    w_i = bnst_dic[ner_id][\"word_id\"][i]\n",
    "                    if type(w_i) is list:\n",
    "                        for j in w_i:\n",
    "                            ner_wc.append(j)\n",
    "                    else:\n",
    "                        ner_wc.append(w_i)\n",
    "                                    \n",
    "                    label = ner_label.replace(\":E\",\"\")\n",
    "                    if label in wh_dic:\n",
    "                        label_name = wh_dic[label]                                \n",
    "                        pred_wh_dic[label_name].append([ner_word,ner_wc]) # データ保存\n",
    "                                \n",
    "                    # 初期化\n",
    "                    ner_word = \"\"\n",
    "                    ner_wc = []\n",
    "                                \n",
    "                elif \":B\" in ner_label or \":I\" in ner_label: # 最初・途中の固有表現\n",
    "                    \n",
    "                    if \"■\" in bnst_dic[ner_id][\"word\"][i]: # 「■」がNER誤判定されていたら、スキップ\n",
    "                        continue\n",
    "                        \n",
    "                    ner_word += bnst_dic[ner_id][\"word\"][i]\n",
    "                    w_i = bnst_dic[ner_id][\"word_id\"][i]\n",
    "                    if type(w_i) is list:\n",
    "                        for j in w_i:\n",
    "                            ner_wc.append(j)\n",
    "                    else:\n",
    "                        ner_wc.append(w_i)\n",
    "                                    \n",
    "                                                                \n",
    "        # NER情報が複数文節に係っている\n",
    "        else:\n",
    "            for i,ner_label in enumerate(ner):\n",
    "                if \":E\" in ner_label: # 最後の固有表現\n",
    "                    w_ner_word += bnst_dic[ner_id][\"word\"][i]\n",
    "                    w_i = bnst_dic[ner_id][\"word_id\"][i]\n",
    "                    \n",
    "                    if type(w_i) is list:\n",
    "                        for j in w_i:\n",
    "                            w_ner_wc.append(j)\n",
    "                    else:\n",
    "                        w_ner_wc.append(w_i)                                \n",
    "                                \n",
    "                    label = ner_label.replace(\":E\",\"\")\n",
    "                    if label in wh_dic:                        \n",
    "                        label_name = wh_dic[label]\n",
    "                        pred_wh_dic[label_name].append([w_ner_word,w_ner_wc]) # データ保存\n",
    "                                \n",
    "                    # 初期化\n",
    "                    w_ner_word = \"\"\n",
    "                    w_ner_wc = []\n",
    "                                \n",
    "                elif \":B\" in ner_label or \":I\" in ner_label: # 最初・途中の固有表現\n",
    "                    \n",
    "                    if \"■\" in bnst_dic[ner_id][\"word\"][i]: # 「■」がNER誤判定されていたら、スキップ\n",
    "                        continue\n",
    "                        \n",
    "                    w_ner_word += bnst_dic[ner_id][\"word\"][i]\n",
    "                    w_i = bnst_dic[ner_id][\"word_id\"][i]\n",
    "                    if type(w_i) is list:\n",
    "                        for j in w_i:\n",
    "                            w_ner_wc.append(j)\n",
    "                    else:\n",
    "                        w_ner_wc.append(w_i)\n",
    "                            \n",
    "    return pred_wh_dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ルール1：Whatの抽出\n",
    "・文節の文末に「を」があるとき、その前の文字が名詞ならば、Whatとして抽出する。\n",
    "\"\"\"\n",
    "def extraction_what(bnst_dic,pred_wh_dic):\n",
    "\n",
    "    for k,v in bnst_dic.items():\n",
    "\n",
    "        if len(v[\"hinsi\"]) >= 2 and \"名詞\" == v[\"hinsi\"][-2] and len(v[\"ner\"][-2]) == 0: # 文節の長さと名詞とNERの有無            \n",
    "            if \"を\" == v[\"word\"][-1] or \"に\" == v[\"word\"][-1] : # 「を/に」                \n",
    "                # 文節末の「を/に」から遡って、続く名詞のindexを調べる\n",
    "                # - pは文末からのindex\n",
    "                # - p_listは文頭からのindex\n",
    "                p_list = []\n",
    "                for i in range(2,len(v[\"hinsi\"])+1):\n",
    "                    p = i * (-1) \n",
    "                    if v[\"hinsi\"][p] == \"名詞\" and len(v[\"ner\"][p]) == 0:\n",
    "                        p_list.append(len(v[\"hinsi\"])+p)                        \n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                # 名詞のindexを元に\n",
    "                wc = []\n",
    "                w = \"\"   \n",
    "                for p_i in sorted(p_list):\n",
    "                    w += v[\"word\"][p_i] \n",
    "                    w_i = v[\"word_id\"][p_i]\n",
    "                    if type(w_i) is list:\n",
    "                        for j in w_i:\n",
    "                            wc.append(j)\n",
    "                    else:\n",
    "                        wc.append(w_i) \n",
    "                \n",
    "                wc = sorted(wc) # 遡って用意したものを、順番に並べる\n",
    "                pred_wh_dic[\"WHAT\"].append([w,wc]) # データ保存\n",
    "                                \n",
    "    return pred_wh_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ルール2：Whatの抽出\n",
    "・動詞節と直接的な係り受け関係のある名詞節を WHAT として抽出する。\n",
    "\"\"\"\n",
    "def new_extraction_what(bnst_dic,verb_list,pred_wh_dic):\n",
    "    \n",
    "    for verb_id in verb_list:\n",
    "\n",
    "        for i in range(verb_id):\n",
    "            if bnst_dic[i][\"parent_id\"] == verb_id and \"動詞\" not in bnst_dic[i][\"hinsi\"]:\n",
    "                \n",
    "                w_txt = \"\"\n",
    "                wc = []\n",
    "                w_flag = True\n",
    "                      \n",
    "                for j,w in enumerate(bnst_dic[i][\"word\"]):\n",
    "                    \n",
    "                    # 単語結合\n",
    "                    w_txt += w\n",
    "                    \n",
    "                    # 単語数\n",
    "                    w_i = bnst_dic[i][\"word_id\"][j]\n",
    "                    if type(w_i) is list:\n",
    "                        for x in w_i:\n",
    "                            wc.append(x)\n",
    "                    else:\n",
    "                        wc.append(w_i)\n",
    "                    \n",
    "                    # NER・「■」有無判定\n",
    "                    if len(bnst_dic[i][\"ner\"][j]) > 0 or \"■\" in bnst_dic[i][\"word\"][j]: \n",
    "                        w_flag = False                    \n",
    "                        break\n",
    "                        \n",
    "                # What候補データ作成\n",
    "                if w_flag:                                 \n",
    "                    pred_wh_dic[\"WHAT\"].append([w_txt,wc]) # データ保存\n",
    "                    \n",
    "    return pred_wh_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# テンプレートを作成する\n",
    "def w2template(pred_wh_dic,text_list):\n",
    "    \n",
    "    template_txt = \"\"\n",
    "    label_ids = []\n",
    "    label_name = {}\n",
    "    \n",
    "    # 4W情報の保存\n",
    "    for k,v in pred_wh_dic.items():\n",
    "        if len(v) != 0:\n",
    "            for v_i in v:\n",
    "                # 要素の最初と最後\n",
    "                sp_s = v_i[1][0]\n",
    "                sp_e = v_i[1][-1] + 1\n",
    "                \n",
    "                # ラベル情報と要素\n",
    "                label_name[sp_e] = k # ラベル情報保存\n",
    "                label_ids.append(sp_s) # 要素の最初\n",
    "                label_ids.append(sp_e) # 要素の最後\n",
    "                      \n",
    "    # テンプレート生成    \n",
    "    data_text = text_list[0] # 1つめのデータを利用\n",
    "\n",
    "    for i,sp in enumerate(sorted(label_ids)):\n",
    "        \n",
    "        if i == 0: # 最初\n",
    "            if sp != 0:\n",
    "                template_txt += data_text[0:sp]\n",
    "                \n",
    "        elif i == (len(label_ids)-1): # 最後\n",
    "            if sp < len(data_text):\n",
    "                template_txt += \"<{0}>\".format(label_name[sp])\n",
    "                template_txt += data_text[sp:len(data_text)]\n",
    "                \n",
    "        elif i%2 == 0:\n",
    "            template_txt += data_text[start_i:sp]\n",
    "        \n",
    "        elif i%2 != 0:\n",
    "            template_txt += \"<{0}>\".format(label_name[sp])\n",
    "            start_i = sp  \n",
    "            \n",
    "    return template_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "# アウトプットファイル\n",
    "ex_file = \"{0}/r{1}_extraction_result.csv\".format(result_path,mode_id) \n",
    "f_file = \"{0}/r{1}_failure_result.csv\".format(result_path,mode_id) \n",
    "ex_txt = \"{0}/r{1}_failure_result.txt\".format(result_path,mode_id)\n",
    "\n",
    "ex_txt_file = open(ex_txt, 'w')  #書き込みモードでオープン\n",
    "output_result = []\n",
    "failure_result = []\n",
    "wh_result = {\"WHERE\":[], \"WHEN\":[], \"WHO\":[], \"WHAT\":[], \"HOW\":[], \"WHY\":[],\"SERIF\":[]}\n",
    "\n",
    "true_wh_list = []\n",
    "pred_wh_list = []\n",
    "\n",
    "for file_id in range(1,data_size+1):\n",
    "    if file_id in skip_file:\n",
    "        continue\n",
    "    \n",
    "    print(file_id)\n",
    "    file_txt = \"{0}{1}.txt\".format(file_info,file_id)\n",
    "    file_ann = \"{0}{1}.ann\".format(file_info,file_id)\n",
    "    \n",
    "    # アノテーションデータ読み込み\n",
    "    true_wh_dic = load_ann(file_ann)\n",
    "\n",
    "    # 5W1H互換表 <MONEY/PERCENT/ARTIFACT>は利用しない\n",
    "    wh_dic = {\"LOCATION\":\"WHERE\", \"TIME\":\"WHEN\",\"DATE\":\"WHEN\",\"ORGANIZATION\":\"WHO\",\"PERSON\":\"WHO\"}\n",
    "    \n",
    "    # knpの5W1H予測結果\n",
    "    pred_wh_dic = {\"WHERE\":[], \"WHEN\":[], \"WHO\":[], \"WHAT\":[], \"HOW\":[], \"WHY\":[],\"SERIF\":[]}\n",
    "    \n",
    "    # テキストデータ読み込み\n",
    "    text_list = []\n",
    "    with open(file_txt,'r') as f:       \n",
    "        for line in f:    \n",
    "            line_list = list(line)\n",
    "            # 括弧を別に保存\n",
    "\n",
    "            match = re.finditer(r\"「(.*?)」\",line)        \n",
    "            for m in match:\n",
    "                \n",
    "                # 括弧の中身を保存する\n",
    "                b_c = []\n",
    "                b_t = \"\"\n",
    "                for i in range(m.start()+1,m.end()-1):\n",
    "                    b_c.append(i)\n",
    "                    b_t += line_list[i]\n",
    "                pred_wh_dic[\"WHAT\"].append([b_t,b_c])\n",
    "                \n",
    "                # 括弧を置換する\n",
    "                bracket = (m.end()-m.start())-1\n",
    "                for i in range(1,bracket):\n",
    "                    line_list[m.start()+i] = \"■\"\n",
    "\n",
    "            text_list.append(\"\".join(line_list))\n",
    "    \n",
    "    word_count = -1 # 単語サイズ\n",
    "    for text in text_list:\n",
    "        for l in text.split(\"。\"):                \n",
    "\n",
    "            if len(l) == 0:\n",
    "                continue\n",
    "                \n",
    "            l = l + \"。\" # 句点を追加する\n",
    "            bnst_dic,ner_list,verb_list,word_count = save_bnst(l,word_count) # 係り受け情報を取得\n",
    "            \n",
    "            # WHERE,WHEN,WHOの抽出 (KNPのNER情報の出力)\n",
    "            if (ner_list) != 0:\n",
    "                pred_wh_dic = extraction_3w(bnst_dic,ner_list,wh_dic,pred_wh_dic)\n",
    "            \n",
    "            # WHATの抽出\n",
    "            if mode_id == 1:\n",
    "                pred_wh_dic = extraction_what(bnst_dic,pred_wh_dic) # ルール1\n",
    "            elif mode_id == 2:\n",
    "                pred_wh_dic = new_extraction_what(bnst_dic,verb_list,pred_wh_dic) # ルール2\n",
    "            else:\n",
    "                sys.stdout.write('Please select a mode.')\n",
    "\n",
    "    # 予測の評価    \n",
    "    result = eval_report(true_wh_dic,pred_wh_dic)\n",
    "    wh_label = [\"WHERE\",\"WHO\",\"WHEN\",\"WHAT\"]\n",
    "    c_r = cal_report(file_id,result,wh_label)\n",
    "    output_result.append(c_r)\n",
    "\n",
    "    # 結果表示\n",
    "    ex_txt_file.writelines(\"==== {0} ====\\n\".format(file_id))\n",
    "    ex_txt_file.writelines(\"{0}\\n\".format(line))\n",
    "    ex_txt_file.writelines(\"\\n\")\n",
    "    ex_txt_file.writelines(\"{0}\\n\".format(pred_wh_dic))\n",
    "    ex_txt_file.writelines(\"{0}\\n\".format(w2template(pred_wh_dic,text_list)))\n",
    "    \n",
    "    ex_txt_file.writelines(\"-----------------------------\\n\")\n",
    "    for wh_l in wh_label:\n",
    "        ex_txt_file.writelines(\"==== {0} ====\\n\".format(wh_l))\n",
    "        ex_txt_file.writelines(\"正解：{0}\\n\".format([t for t in true_wh_dic[wh_l]]))\n",
    "        ex_txt_file.writelines(\"予想：{0}\\n\".format([t for t in pred_wh_dic[wh_l]]))\n",
    "        ex_txt_file.writelines(\"ラベル誤り：{0}\\n\".format(result[wh_l][\"ラベル誤り\"]))\n",
    "        ex_txt_file.writelines(\"抽出漏れ：{0}\\n\".format(result[wh_l][\"抽出漏れ\"]))\n",
    "        ex_txt_file.writelines(\"過度の抽出：{0}\\n\".format(result[wh_l][\"過度の抽出\"]))\n",
    "\n",
    "    ex_txt_file.writelines(\"-----------------------------\\n\") \n",
    "    ex_txt_file.writelines(\"{0}\\n\".format([\"記事id\",\"完全\",\"一部一致\",\"ラベル誤り\",\"抽出漏れ\",\"過度の抽出\"]))\n",
    "    ex_txt_file.writelines(\"{0}\\n\".format(c_r))\n",
    "    \n",
    "    # 1記事における5w1hラベルごとの結果\n",
    "    for k,v in cal_report_wh(file_id,result).items():\n",
    "        wh_result[k].append(v) \n",
    "      \n",
    "    # 失敗データのリスト化\n",
    "    for wh_l in wh_label:\n",
    "        for rt in result[wh_l][\"ラベル誤り\"]:\n",
    "            failure_result.append([file_id,wh_l,\"ラベル誤り\",rt])\n",
    "        for rt in result[wh_l][\"抽出漏れ\"]:\n",
    "            failure_result.append([file_id,wh_l,\"抽出漏れ\",rt])\n",
    "        for rt in result[wh_l][\"過度の抽出\"]:\n",
    "            failure_result.append([file_id,wh_l,\"過度の抽出\",rt])\n",
    "\n",
    "ex_txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ファイル書き込み\n",
    "# 評価結果\n",
    "with open(ex_file, 'w') as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n') # 改行コード（\\n）を指定しておく\n",
    "    writer.writerow([\"記事id\",\"完全\",\"一部一致\",\"ラベル誤り\",\"抽出漏れ\",\"過度の抽出\"])\n",
    "    for o_data in output_result:\n",
    "        writer.writerow(o_data)\n",
    "        \n",
    "# 失敗データ\n",
    "with open(f_file, 'w') as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n') # 改行コード（\\n）を指定しておく\n",
    "    writer.writerow([\"記事id\",\"ラベル\",\"失敗タイプ\",\"単語\",\"原因\"])\n",
    "    for f_data in failure_result:\n",
    "        writer.writerow(f_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
